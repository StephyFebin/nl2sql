{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5d9f1ea-dd24-4497-8415-1f9b67199147",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d3d099-1390-416a-9ed6-b86eec29fefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-admin_user_name/myenv_new/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import os \n",
    "import re\n",
    "import autogen\n",
    "from autogen import AssistantAgent,ChatResult\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pymongo import MongoClient\n",
    "import mlflow\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.core.schema import Document\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from autogen.agentchat.contrib.retrieve_user_proxy_agent import RetrieveUserProxyAgent\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    " \n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3a9176d-7c56-483e-a4de-dc79cf71b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Openai - api key\n",
    " \n",
    "import openai\n",
    "openai.api_key =  \"######\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3809c378-25d9-47c4-aeae-b66ca61d307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_summary(summary_out):\n",
    "    scores = re.findall(r'- ([\\w\\s]+): (\\d+)', summary_out)\n",
    "    score_df = pd.DataFrame(scores, columns=[\"Metric\", \"Score\"])\n",
    "\n",
    "    judgment = re.search(r'\\*\\*Judgment\\*\\*: (.+)', summary_out)\n",
    "    reason = re.search(r'\\*\\*Reason\\*\\*: (.+)', summary_out, re.DOTALL)\n",
    "\n",
    "    return (\n",
    "        judgment.group(1).strip() if judgment else \"N/A\",\n",
    "        score_df,\n",
    "        reason.group(1).strip() if reason else \"N/A\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7e97ffb-ac8c-4ee6-826b-c7dae7b8772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "mlflow.set_experiment(\"AI_SQL_Generation\")\n",
    " \n",
    "\n",
    "def execute_sql_query(query, db_path=\"spider_db/spider_db_baseball.db\"):\n",
    "    \"\"\"Execute SQL query and track execution metrics using MLflow.\"\"\"\n",
    "    try:\n",
    "        with mlflow.start_run(run_name=\"Execute_SQL_Query\"):\n",
    "            mlflow.log_param(\"query\", query)\n",
    "        \n",
    "        conn = sqlite3.connect(db_path)\n",
    "        df = pd.read_sql_query(query, conn)\n",
    "\n",
    "        # Save DataFrame to a CSV file locally\n",
    "        csv_path = \"sql_result.csv\"\n",
    "        df.to_csv(csv_path, index=False)\n",
    "\n",
    "        with mlflow.start_run(run_name=\"SQL_Execution_Results\"):\n",
    "        # Log the CSV file as an artifact so you can view/download it via the MLflow UI\n",
    "            mlflow.log_artifact(csv_path, artifact_path=\"sql_results\")\n",
    " \n",
    "        \n",
    "        return df, None\n",
    "    except Exception as e:\n",
    "        with mlflow.start_run(run_name=\"SQL_Error_Logging\"):\n",
    "            mlflow.log_param(\"error\", str(e))\n",
    "        return None, f\"❌ SQL Execution Error: {str(e)}\"\n",
    "    finally:\n",
    "        if 'conn' in locals():\n",
    "            conn.close()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "187ae4ff-8e12-48f8-8890-e2dbffbb85df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------------------- MongoDB Memory Setup --------------------- #\n",
    "mongo_client = MongoClient(\"mongodb://127.0.0.1:27017\")\n",
    " \n",
    " \n",
    "mongo_db = mongo_client[\"memory_database\"]\n",
    "short_term_collection = mongo_db[\"session_memory\"]\n",
    "long_term_collection = mongo_db[\"user_memory\"]\n",
    "\n",
    "# Function to store session-based memory (Short-Term)\n",
    "def store_short_term_memory(session_id, user_id, query, mood):\n",
    "    \"\"\"Stores session-based queries & mood tracking.\"\"\"\n",
    "    short_term_collection.update_one(\n",
    "        {\"session_id\": session_id},\n",
    "        {\n",
    "            \"$set\": {\"current_mood\": mood, \"user_id\": user_id},\n",
    "            \"$push\": {\"previous_queries\": query}  # Append session queries\n",
    "        },\n",
    "        upsert=True\n",
    "    )\n",
    "\n",
    "# Function to retrieve session memory\n",
    "def retrieve_short_term_memory(session_id):\n",
    "    \"\"\"Fetch session-based query memory and mood tracking.\"\"\"\n",
    "    session_data = short_term_collection.find_one({\"session_id\": session_id})\n",
    "    if not session_data:\n",
    "        return {\"previous_queries\": [], \"current_mood\": \"Neutral\"}\n",
    "    return {\n",
    "        \"previous_queries\": session_data.get(\"previous_queries\", []),\n",
    "        \"current_mood\": session_data.get(\"current_mood\", \"Neutral\")\n",
    "    }\n",
    "\n",
    "# Function to store long-term user preferences & query history\n",
    "def store_long_term_memory(user_id, query, mood, preferences=None, demographics=None):\n",
    "    \"\"\"Stores persistent user query history & personalization details.\"\"\"\n",
    "    long_term_collection.update_one(\n",
    "        {\"user_id\": user_id},\n",
    "        {\n",
    "            \"$set\": {\n",
    "                \"last_mood\": mood,\n",
    "                \"preferences\": preferences,\n",
    "                \"demographics\": demographics\n",
    "            },\n",
    "            \"$push\": {\"query_history\": query}  # Append to past queries\n",
    "        },\n",
    "        upsert=True\n",
    "    )\n",
    "\n",
    "# Function to retrieve long-term memory\n",
    "def retrieve_long_term_memory(user_id):\n",
    "    \"\"\"Fetch user preferences, expertise level, and past queries.\"\"\"\n",
    "    user_data = long_term_collection.find_one({\"user_id\": user_id})\n",
    "    if not user_data:\n",
    "        return None\n",
    "    return {\n",
    "        \"preferences\": user_data.get(\"preferences\", {}),\n",
    "        \"demographics\": user_data.get(\"demographics\", {}),\n",
    "        \"query_history\": user_data.get(\"query_history\", []),\n",
    "        \"last_mood\": user_data.get(\"last_mood\", \"Neutral\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65e787db-17c4-46e0-8991-0b080fe4be39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def detect_mood_from_query(query):\n",
    "    \"\"\"Infer user mood using sentiment analysis.\"\"\"\n",
    "    sentiment_score = TextBlob(query).sentiment.polarity\n",
    "    with mlflow.start_run(run_name=\"Mood_Analysis\"):\n",
    "        mlflow.log_param(\"query_text\", query)\n",
    "        mlflow.log_metric(\"sentiment_score\", sentiment_score)\n",
    "    return \"Curious\" if sentiment_score > 0.3 else \"Frustrated\" if sentiment_score < -0.3 else \"Neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70a175bc-e510-4588-b1bd-8f7ab03ed5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "\n",
    "# === Step 1: Configure OpenAI Embeddings ===\n",
    "Settings.embed_model = OpenAIEmbedding()  # or ada-002, etc.\n",
    "\n",
    "# === Step 2: Load Documents from Directory ===\n",
    "directory_docs = SimpleDirectoryReader(\"./docs\").load_data()\n",
    "\n",
    "# === Step 3: Load SQLite Schema as Document ===\n",
    "def load_sqlite_schema_as_docs(sqlite_path):\n",
    "    conn = sqlite3.connect(sqlite_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tables = cursor.fetchall()\n",
    "\n",
    "    documents = []\n",
    "    for (table_name,) in tables:\n",
    "        cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "        columns = cursor.fetchall()\n",
    "        schema_text = f\"Table: {table_name}\\n\"\n",
    "        for col in columns:\n",
    "            schema_text += f\"  - {col[1]} ({col[2]})\\n\"\n",
    "        documents.append(Document(text=schema_text))\n",
    "\n",
    "    conn.close()\n",
    "    return documents\n",
    "\n",
    "# === Step 4: Load SQLite documents ===\n",
    "sqlite_docs = load_sqlite_schema_as_docs(\"spider_db/spider_db_baseball.db\")  # your path\n",
    "\n",
    "# === Step 5: Combine both sets of documents ===\n",
    "all_documents = directory_docs + sqlite_docs\n",
    "\n",
    "# === Step 6: Create the index ===\n",
    "index = VectorStoreIndex.from_documents(all_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37255439-d900-4efa-a778-ac6593cb9a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_action(user_query, session_id,user_id):\n",
    "    config_list = {\n",
    "    \"model\": \"llama-3.3-70b-versatile\",\n",
    "    \"api_key\": \"##########\",\n",
    "    \"api_type\": \"groq\"\n",
    "    }\n",
    "    os.environ[\"AUTOGEN_USE_DOCKER\"] = \"False\"\n",
    "\n",
    "    session_data = retrieve_short_term_memory(session_id)\n",
    "    previous_queries = session_data[\"previous_queries\"]\n",
    "    session_mood = session_data[\"current_mood\"]\n",
    "\n",
    "     # Retrieve long-term memory (past interactions)\n",
    "    user_context = retrieve_long_term_memory(user_id)\n",
    "    if user_context is None:\n",
    "        user_context = {}\n",
    "    long_term_queries = user_context.get(\"query_history\", [])\n",
    "    preferences = user_context.get(\"preferences\", {})\n",
    "    demographics = user_context.get(\"demographics\", {})\n",
    "    last_mood = user_context.get(\"last_mood\", \"Neutral\")\n",
    "\n",
    "    # Detect mood dynamically from user query\n",
    "    current_mood = detect_mood_from_query(user_query)\n",
    "\n",
    "    # Update memory stores\n",
    "    store_short_term_memory(session_id, user_id, user_query, current_mood)\n",
    "    store_long_term_memory(user_id, user_query, current_mood, preferences, demographics)\n",
    "\n",
    "     \n",
    "\n",
    "    # Step 2: Create a retriever from that index\n",
    "    retriever = VectorIndexRetriever(index=index)\n",
    "\n",
    "    assistant = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    llm_config=config_list,\n",
    "    system_message=(\n",
    "            f\"You are an AI assistant generating SQL queries.\\n\"\n",
    "            f\"User's previous session queries: {previous_queries}\\n\"\n",
    "            f\"Long-term query history: {long_term_queries}\\n\"\n",
    "            f\"Current mood: {current_mood}, previous moods: {last_mood}\\n\"\n",
    "            f\"Preferred format: {preferences.get('preferred_format', 'table')}\\n\"\n",
    "            f\"User expertise level: {demographics.get('experience_level', 'Intermediate')}\\n\"\n",
    "            \"Generate responses tailored to query patterns, mood, and expertise level.\"\n",
    "        )\n",
    " \n",
    "    )\n",
    "    ragproxyagent = RetrieveUserProxyAgent(\n",
    "        name=\"ragproxyagent\",\n",
    "        retrieve_config={\n",
    "            \"task\": \"qa\",\n",
    "            \"custom_retriever\": retriever,\n",
    "            \"overwrite\": True\n",
    "    \n",
    "        },\n",
    "   \n",
    "    )\n",
    "    assistant.reset()\n",
    "    ragproxyagent.reset()\n",
    "    with mlflow.start_run(run_name=\"LLM_Query_Generation\"):\n",
    "        mlflow.log_param(\"user_query\", user_query)\n",
    "\n",
    "    \n",
    "    result =ragproxyagent.initiate_chat(assistant, message=ragproxyagent.message_generator,\n",
    "                                        max_round=2,problem=user_query,\n",
    "                                        speaker_selection_method=\"round_robin\",  # Ensures agents take turns\n",
    "        allow_repeat_speaker=False,\n",
    "        max_turns=1)\n",
    "    for message in result.chat_history:\n",
    "        if message[\"role\"] == \"user\" and message.get(\"name\") == \"assistant\":\n",
    "            content = message[\"content\"]\n",
    "            # Extract everything between ```sql and ``` (if that format is used)\n",
    "            if \"```sql\" in content and \"```\" in content:\n",
    "                start = content.index(\"```sql\") + len(\"```sql\")\n",
    "                end = content.index(\"```\", start)\n",
    "                generated_query = content[start:end].strip()\n",
    "            else:\n",
    "                generated_query = content.strip()\n",
    "            break\n",
    "         \n",
    "    validator = AssistantAgent(\n",
    "    name=\"validator\",\n",
    "    llm_config=config_list,\n",
    "    system_message=(\n",
    "        f\"You are a SQL Validator. Review the {generated_query} query and validate it against the provided schema. \"\n",
    "        \"Check for syntax errors, missing columns/tables, and logical issues. \"\n",
    "        \"Respond with one of the following:\\n\\n\"\n",
    "        \"- ✅ Valid SQL: If the query is correct.\\n\"\n",
    "        \"- ❌ Invalid SQL: If the query has issues. Explain the problem clearly.\"\n",
    "        ),\n",
    "    \n",
    "    )\n",
    "    \n",
    "    judge = AssistantAgent(\n",
    "        name=\"judge\",\n",
    "        system_message=(\n",
    "            f\"You are a Judge Agent. Review the user question, the generated SQL query, and the validator’s feedback. \"\n",
    "            \"Evaluate the query based on the following 6 metrics and provide scores between 0 and 10:\\n\\n\"\n",
    "            \n",
    "            \"1. Accuracy (0–10): Does the AI-generated SQL return the same results as the reference SQL when executed on the same database?\\n\"\n",
    "            \"- 10: Identical results\\n\"\n",
    "            \"- 5: Partial match (e.g., missing filters, subset/superset of rows)\\n\"\n",
    "            \"- 0: Incorrect or different logic\\n\\n\"\n",
    "            \n",
    "            \"2. Efficiency (0–10): Evaluate the query's performance in terms of execution time, indexing, and join optimization.\\n\"\n",
    "            \"- 10: Highly efficient (<1s, optimized with indexes and joins)\\n\"\n",
    "            \"- 6: Moderate (1–3s, room for improvement)\\n\"\n",
    "            \"- 3: Low efficiency (>3s, full scans or nested loops)\\n\\n\"\n",
    "            \n",
    "            \"3. Hallucination (0–10): Check for invalid elements like non-existent tables, columns, or illogical clauses.\\n\"\n",
    "            \"- 0: No hallucination\\n\"\n",
    "            \"- 5: Minor (1–2 issues)\\n\"\n",
    "            \"- 10: Major hallucinations (e.g., many or critical invalid references)\\n\\n\"\n",
    "            \n",
    "            \"4. Completeness (0–10): Does the query fully answer the user’s question?\\n\"\n",
    "            \"- 10: Fully complete\\n\"\n",
    "            \"- 5: Partially complete (some logic or filters missing)\\n\"\n",
    "            \"- 0: Incomplete or irrelevant\\n\\n\"\n",
    "            \n",
    "            \"5. Structure Similarity (0–10): Are similar joins, filters, subqueries, and groupings used as in the reference?\\n\"\n",
    "            \"- 10: Very similar\\n\"\n",
    "            \"- 6: Moderately similar\\n\"\n",
    "            \"- 2: Very different\\n\\n\"\n",
    "            \n",
    "            \"6. Readability & Maintainability (0–10): Is the SQL query easy to read, well-formatted, and maintainable?\\n\"\n",
    "            \"- 10: Excellent\\n\"\n",
    "            \"- 7: Good\\n\"\n",
    "            \"- 4: Fair\\n\"\n",
    "            \"- 1: Poor\\n\\n\"\n",
    "            \n",
    "            \"7. Overall Score (0–10): Compute using the formula:\\n\"\n",
    "            \"   score = round(0.3 * accuracy + 0.15 * efficiency + 0.15 * (10 - hallucination) + \"\n",
    "            \"0.2 * completeness + 0.1 * structure_similarity + 0.1 * readability)\\n\\n\"\n",
    "            \n",
    "            \"Respond in this format:\\n\"\n",
    "            \"**Judgment**: Good / Needs Improvement\\n\"\n",
    "            \"**Scores**:\\n\"\n",
    "            \"- Accuracy: X\\n\"\n",
    "            \"- Efficiency: X\\n\"\n",
    "            \"- Hallucination: X\\n\"\n",
    "            \"- Completeness: X\\n\"\n",
    "            \"- Structure Similarity: X\\n\"\n",
    "            \"- Readability: X\\n\"\n",
    "            \"- Overall Score: X\\n\"\n",
    "            \"**Reason**: <Brief explanation>\"\n",
    "        ),\n",
    "        llm_config=config_list,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    groupchat = autogen.GroupChat(\n",
    "        agents=[validator,judge],\n",
    "        messages=[],\n",
    "        max_round=5,\n",
    "        speaker_transitions_type=\"allowed\",\n",
    "        speaker_selection_method=\"round_robin\",  # Ensures agents take turns\n",
    "        allow_repeat_speaker=False\n",
    "        )\n",
    "    \n",
    "    manager = autogen.GroupChatManager(\n",
    "            groupchat=groupchat, llm_config={\"config_list\": config_list},\n",
    "            is_termination_msg=lambda msg: (\n",
    "            isinstance(msg, dict) and\n",
    "            msg.get(\"name\") == \"judge\" and\n",
    "            bool(msg.get(\"content\"))  # Ensure content is not empty\n",
    "        )\n",
    "        )\n",
    "    chat_result = manager.initiate_chat(\n",
    "        manager,\n",
    "        max_turns=1,\n",
    "        message = f\"Analyze the sql query : {generated_query}\"\n",
    "        )\n",
    "    judge_entry = next(\n",
    "    (msg['content'] for msg in groupchat.messages if msg['name'] == 'judge'),\n",
    "    None\n",
    "    )\n",
    "\n",
    "    if judge_entry:\n",
    "        # Save the judge's feedback to a file\n",
    "        with open(\"judge_evaluation.txt\", \"w\") as f:\n",
    "            f.write(judge_entry)\n",
    "        \n",
    "        # Log the feedback artifact and optionally, metrics (if you parse them)\n",
    "        with mlflow.start_run(run_name=\"LLM_Evaluation_Results\"):\n",
    "            mlflow.log_artifact(\"judge_evaluation.txt\", artifact_path=\"evaluation\")\n",
    "            \n",
    "            # Additional: If you can parse out numeric metrics, log them:\n",
    "            # For example, assume you extract metrics into a dictionary:\n",
    "            # evaluation_metrics = {\"accuracy\": 8, \"efficiency\": 7, ...}\n",
    "            # for key, value in evaluation_metrics.items():\n",
    "            #     mlflow.log_metric(key, value)\n",
    "    else:\n",
    "        print(\"No entry found from 'judge'\")\n",
    "   \n",
    "    df,error = execute_sql_query(generated_query)\n",
    "    \n",
    "    if error:\n",
    "        return generated_query, \"Query failed.\", pd.DataFrame(), error, []  # or however you want to handle\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    store_short_term_memory(session_id, user_id, generated_query, current_mood)\n",
    "    data_analyst = AssistantAgent(\n",
    "    name=\"data_analyst\",\n",
    "    llm_config=config_list,\n",
    "    system_message=(\n",
    "        \"You are a Data Analyst Agent.\\n\"\n",
    "        \"After retrieving the data:\\n\"\n",
    "        \"1. If the data supports a clear report (like customer details, summaries, etc.), generate a short and also detailed analytical report.\\n\"\n",
    "        \"2. If the data supports visual representation (like trends, numerical summaries, categories), suggest a few types of graphs and describe what each would show.\\n\"\n",
    "        \"3. If the data is minimal or purely textual, generate a brief plain text summary. And also need the detailed summary also\\n\\n\"\n",
    "        \"If it is possible to create graphs based on the data, suggest the following types of graphs (if applicable):\\n\"\n",
    "        \"    - Bar Chart: To show frequency or counts of categorical data.\\n\"\n",
    "        \"    - Line Chart: To show trends over time.\\n\"\n",
    "        \"    - Pie Chart: To represent proportions or parts of a whole.\\n\"\n",
    "        \"    - Histogram: To visualize the distribution of numerical data.\\n\"\n",
    "        \"    - Box Plot: To visualize the distribution and identify outliers.\\n\\n\"\n",
    "        \"If the data supports any of these graphs, provide the Python code to generate the graph and save it as a .jpg image. If not, simply state that no graphical representation is possible and provide only the analysis and summary of the data.\\n\\n\"\n",
    "        \"Be concise, professional, and assume the reader is a business stakeholder.\\n\"\n",
    "        \"the data frame name should be df and no need to initialize\"\n",
    "        \"Analysed Relevent and unique information  need in should be in table format. no code\"\n",
    "        \"graph image location should be graph/ then the image name\"\n",
    "        \"Format your output as follows:\\n\\n\"\n",
    "        \"**Query**:\\n<query>\\n\\n\"\n",
    "        \"**Data Snapshot**:\\n<first 5 rows of the data>\\n\\n\"\n",
    "        \"**Analysis**:\\n<brief summary>\\n\\n\"\n",
    "        \"**Detailed Analysis**:\\n<Analysed Relevent and unique information  need in should be in table format. no code>\\n\\n\"\n",
    "        \"**Report or Graph Suggestions**:\\n<graph recommendations and corresponding Python code, or 'No graphical representation is possible'>\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    \n",
    "    message_text = (\n",
    "        f\"**SQL Query**:\\n{generated_query}\\n\\n\"\n",
    "        f\"**Fetched Data (Top Rows)**:\\n{df}\\n\\n\"\n",
    "        \"Please analyze the data accordingly.\"\n",
    "    )\n",
    "    \n",
    "    data_analyst.reset()\n",
    "    chat_results = data_analyst.initiate_chat(data_analyst, message=message_text,max_turns=1)\n",
    "    graph_images = extract_and_run_graphs(chat_results.chat_history, df)\n",
    "    graph_suggestions = extract_graph_suggestions(chat_results.chat_history)\n",
    "    graph_types = parse_graph_types(graph_suggestions)\n",
    "    print('000000000000000000000000000000000',graph_types)\n",
    " \n",
    "    \n",
    "    return generated_query,judge_entry,df,graph_images,gr.update(choices=graph_types), chat_results.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccfc5ebc-5876-4f0a-8278-c0541ac99bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_and_run_graphs(chat_history, df):\n",
    "    python_code_blocks = []\n",
    "    saved_images = []\n",
    "\n",
    "    # Regex to extract Python code blocks\n",
    "    code_block_pattern = re.compile(r\"```python(.*?)```\", re.DOTALL)\n",
    "\n",
    "    # Loop through chat messages and extract Python code\n",
    "    for message in chat_history:\n",
    "        if message.get(\"name\") != \"data_analyst\":\n",
    "            continue\n",
    "\n",
    "        content = message.get(\"content\", \"\")\n",
    "        matches = code_block_pattern.findall(content)\n",
    "\n",
    "        for code in matches:\n",
    "            code = code.strip()\n",
    "            python_code_blocks.append(code)\n",
    "\n",
    "    # Execute each code block in a shared context with 'df' available\n",
    "    exec_globals = {\"df\": df, \"plt\": plt, \"os\": os}\n",
    "    for i, code_block in enumerate(python_code_blocks):\n",
    "        print(f\"\\n▶ Executing graph code block {i + 1}:\\n{code_block}\\n\")\n",
    "        try:\n",
    "            # Attempt to detect and capture any plt.savefig(...) call for image path\n",
    "            save_match = re.search(r\"plt\\.savefig\\(['\\\"](.*?)['\\\"]\\)\", code_block)\n",
    "            if save_match:\n",
    "                filename = save_match.group(1)\n",
    "            else:\n",
    "                filename = None\n",
    "\n",
    "            exec(code_block, exec_globals)\n",
    "\n",
    "            if filename and os.path.exists(filename):\n",
    "                saved_images.append(filename)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in graph code block {i + 1}: {e}\")\n",
    "\n",
    "    return saved_images  # You can return this list to show in Gradio or elsewhere\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38bffa48-d767-427e-808e-920cc0741284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def extract_graph_suggestions(chat_history):\n",
    "    # Extract graph suggestions from the chat history (or wherever the suggestion comes from)\n",
    "    suggestions = \"\"\n",
    "    for message in chat_history:\n",
    "        if \"Report or Graph Suggestions\" in message.get(\"content\", \"\"):\n",
    "            suggestions = message[\"content\"]\n",
    "            break\n",
    "    return suggestions\n",
    "\n",
    "\n",
    "\n",
    "def parse_graph_types(suggestions):\n",
    "    # Example of extracting graph types from the suggestion text\n",
    "    graph_types = []\n",
    "    if \"Bar Chart\" in suggestions:\n",
    "        graph_types.append(\"Bar Chart\")\n",
    "    if \"Pie Chart\" in suggestions:\n",
    "        graph_types.append(\"Pie Chart\")\n",
    "    if \"Line Chart\" in suggestions:\n",
    "        graph_types.append(\"Line Chart\")\n",
    "    if \"Box Plot\" in suggestions:\n",
    "        graph_types.append(\"Box Plot\")\n",
    "    return graph_types\n",
    "def create_custom_chart(df, chart_type, x_col, y_col):\n",
    "    # Ensure that the columns you want to plot do not contain NaN or None values\n",
    "    df = df.dropna(subset=[x_col, y_col])  # Remove rows where either x or y is NaN or None\n",
    "    \n",
    "    # Check if the dataframe is empty after dropping NaN values\n",
    "    if df.empty:\n",
    "        return \"Error: No valid data available for plotting.\"\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    if chart_type == \"Bar Chart\":\n",
    "        plt.bar(df[x_col], df[y_col], color='skyblue')\n",
    "        plt.xlabel(x_col)\n",
    "        plt.ylabel(y_col)\n",
    "        plt.title(f\"{chart_type}: {y_col} by {x_col}\")\n",
    "    elif chart_type == \"Pie Chart\":\n",
    "        data = df.groupby(x_col)[y_col].sum()\n",
    "        plt.pie(data, labels=data.index, autopct=\"%1.1f%%\")\n",
    "        plt.title(f\"{chart_type}: {y_col} by {x_col}\")\n",
    "    elif chart_type == \"Line Chart\":\n",
    "        plt.plot(df[x_col], df[y_col], marker='o', color='b')\n",
    "        plt.xlabel(x_col)\n",
    "        plt.ylabel(y_col)\n",
    "        plt.title(f\"{chart_type}: {y_col} by {x_col}\")\n",
    "    elif chart_type == \"Box Plot\":\n",
    "        plt.boxplot([df[y_col]], labels=[x_col])\n",
    "        plt.ylabel(y_col)\n",
    "        plt.title(f\"{chart_type}: {y_col} by {x_col}\")\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    path = \"graph/custom_graph.jpg\"\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "    with mlflow.start_run(run_name=\"Custom_Graph_Generation\"):\n",
    "        mlflow.log_artifact(path, artifact_path=\"custom_graphs\")\n",
    "\n",
    "    return path\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32ea9e14-cc4f-4c78-ba2d-ffec708732c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://2fbb9a3ee7a7f50617.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://2fbb9a3ee7a7f50617.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "import matplotlib.pyplot as plt\n",
    "def extract_graph_suggestions(chat_history):\n",
    "    # Extract graph suggestions from the chat history (or wherever the suggestion comes from)\n",
    "    suggestions = \"\"\n",
    "    for message in chat_history:\n",
    "        if \"Report or Graph Suggestions\" in message.get(\"content\", \"\"):\n",
    "            suggestions = message[\"content\"]\n",
    "            break\n",
    "    return suggestions\n",
    "\n",
    "def parse_graph_types(suggestions):\n",
    "    # Example of extracting graph types from the suggestion text\n",
    "    graph_types = []\n",
    "    if \"Bar Chart\" in suggestions:\n",
    "        graph_types.append(\"Bar Chart\")\n",
    "    if \"Pie Chart\" in suggestions:\n",
    "        graph_types.append(\"Pie Chart\")\n",
    "    if \"Line Chart\" in suggestions:\n",
    "        graph_types.append(\"Line Chart\")\n",
    "    if \"Box Plot\" in suggestions:\n",
    "        graph_types.append(\"Box Plot\")\n",
    "    return graph_types\n",
    "def create_custom_chart(df, chart_type, x_col, y_col):\n",
    "    # Ensure that the columns you want to plot do not contain NaN or None values\n",
    "    df = df.dropna(subset=[x_col, y_col])  # Remove rows where either x or y is NaN or None\n",
    "    \n",
    "    # Check if the dataframe is empty after dropping NaN values\n",
    "    if df.empty:\n",
    "        return \"Error: No valid data available for plotting.\"\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    if chart_type == \"Bar Chart\":\n",
    "        plt.bar(df[x_col], df[y_col], color='skyblue')\n",
    "        plt.xlabel(x_col)\n",
    "        plt.ylabel(y_col)\n",
    "        plt.title(f\"{chart_type}: {y_col} by {x_col}\")\n",
    "    elif chart_type == \"Pie Chart\":\n",
    "        data = df.groupby(x_col)[y_col].sum()\n",
    "        plt.pie(data, labels=data.index, autopct=\"%1.1f%%\")\n",
    "        plt.title(f\"{chart_type}: {y_col} by {x_col}\")\n",
    "    elif chart_type == \"Line Chart\":\n",
    "        plt.plot(df[x_col], df[y_col], marker='o', color='b')\n",
    "        plt.xlabel(x_col)\n",
    "        plt.ylabel(y_col)\n",
    "        plt.title(f\"{chart_type}: {y_col} by {x_col}\")\n",
    "    elif chart_type == \"Box Plot\":\n",
    "        plt.boxplot([df[y_col]], labels=[x_col])\n",
    "        plt.ylabel(y_col)\n",
    "        plt.title(f\"{chart_type}: {y_col} by {x_col}\")\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    path = \"graph/custom_graph.jpg\"\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "    with mlflow.start_run(run_name=\"Custom_Graph_Generation\"):\n",
    "        mlflow.log_artifact(path, artifact_path=\"custom_graphs\")\n",
    "\n",
    "    return path\n",
    " \n",
    "\n",
    "\n",
    "def generate_summary_pdf(summary_text, df):\n",
    "    import os, re, uuid, shutil, tempfile\n",
    "    from reportlab.lib.pagesizes import letter\n",
    "    from reportlab.lib import colors\n",
    "    from reportlab.pdfgen import canvas\n",
    "    from reportlab.lib.styles import getSampleStyleSheet\n",
    "    from reportlab.platypus import Table, TableStyle\n",
    "    from reportlab.lib.utils import ImageReader\n",
    "    from reportlab.lib.utils import simpleSplit\n",
    "    import matplotlib.pyplot as plt\n",
    "    import glob\n",
    "    for f in glob.glob(os.path.join('graph', \"*\")):\n",
    "        try:\n",
    "            os.remove(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not delete {f}: {e}\")\n",
    "    \n",
    "    for f in glob.glob(os.path.join('reports', \"*\")):\n",
    "        try:\n",
    "            os.remove(f)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not delete {f}: {e}\")\n",
    "    \n",
    "    filename = f\"summary_{uuid.uuid4().hex}.pdf\"\n",
    "    filepath = os.path.join(\"reports\", filename)\n",
    "    os.makedirs(\"reports\", exist_ok=True)\n",
    "    \n",
    "\n",
    "    # Setup canvas\n",
    "    c = canvas.Canvas(filepath, pagesize=letter)\n",
    "    width, height = letter\n",
    "    left_margin, top_margin, bottom_margin = 50, 50, 50\n",
    "    max_width = width - 2 * left_margin\n",
    "    line_height = 15\n",
    "\n",
    "    # Draw page border\n",
    "    c.setLineWidth(1)\n",
    "    c.rect(20, 20, width - 40, height - 40)\n",
    "\n",
    "    # Heading\n",
    "    heading_text = \"SQL Query Summary Report\"\n",
    "    c.setFont(\"Times-BoldItalic\", 18)\n",
    "    c.drawString(left_margin, height - top_margin, heading_text)\n",
    "    heading_width = c.stringWidth(heading_text, \"Times-BoldItalic\", 18)\n",
    "    c.setLineWidth(1)\n",
    "    c.line(left_margin, height - top_margin - 5, left_margin + heading_width, height - top_margin - 5)\n",
    "    y = height - top_margin - 35\n",
    "\n",
    "   \n",
    " \n",
    "\n",
    "    # Extract sections\n",
    "    sections = {\"Query\": \"\", \"Data Snapshot\": \"\", \"Analysis\": \"\", \"Detailed Analysis\": \"\"}\n",
    "    current = None\n",
    "    for line in summary_text.split('\\n'):\n",
    "        match = re.match(r\"\\*\\*(.*?)\\*\\*:\", line)\n",
    "        if match:\n",
    "            current = match.group(1)\n",
    "            continue\n",
    "        if current in sections:\n",
    "            sections[current] += line + \"\\n\"\n",
    "\n",
    "    # Write block of wrapped text\n",
    "    def write_text_block(text):\n",
    "        nonlocal y\n",
    "        for line in text.strip().split(\"\\n\"):\n",
    "            wrapped = simpleSplit(line, \"Helvetica\", 12, max_width)\n",
    "            for wline in wrapped:\n",
    "                if y <= bottom_margin:\n",
    "                    c.showPage()\n",
    "                    c.setFont(\"Helvetica\", 12)\n",
    "                    c.rect(20, 20, width - 40, height - 40)\n",
    "                    y = height - top_margin\n",
    "                c.drawString(left_margin, y, wline)\n",
    "                y -= line_height\n",
    "\n",
    "    # Render sections\n",
    "    for title, content in sections.items():\n",
    "        c.setFont(\"Helvetica-Bold\", 12)\n",
    "        if y <= bottom_margin:\n",
    "            c.showPage()\n",
    "            c.setFont(\"Helvetica\", 12)\n",
    "            c.rect(20, 20, width - 40, height - 40)\n",
    "            y = height - top_margin\n",
    "        c.drawString(left_margin, y, title)\n",
    "        y -= line_height\n",
    "        c.setFont(\"Helvetica\", 12)\n",
    "\n",
    "        def draw_wrapped_table(content, styles):\n",
    "            nonlocal y\n",
    "            try:\n",
    "                table_data = [re.split(r'\\s*\\|\\s*', line.strip())[1:-1] for line in content.strip().splitlines() if '|' in line]\n",
    "                if not table_data:\n",
    "                    raise ValueError(\"No valid table data\")\n",
    "                col_count = len(table_data[0])\n",
    "                col_widths = [max_width / col_count] * col_count\n",
    "                table = Table(table_data, colWidths=col_widths)\n",
    "                table.setStyle(styles)\n",
    "                w, h = table.wrap(max_width, y - bottom_margin)\n",
    "                if y - h < bottom_margin:\n",
    "                    c.showPage()\n",
    "                    c.setFont(\"Helvetica\", 12)\n",
    "                    c.rect(20, 20, width - 40, height - 40)\n",
    "                    y = height - top_margin\n",
    "                table.drawOn(c, left_margin, y - h)\n",
    "                y -= h + 20\n",
    "            except Exception as e:\n",
    "                write_text_block(\"Failed to render table.\")\n",
    "\n",
    "        if title == \"Data Snapshot\":\n",
    "            draw_wrapped_table(content, TableStyle([\n",
    "                ('BACKGROUND', (0, 0), (-1, 0), colors.grey),\n",
    "                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),\n",
    "                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),\n",
    "                ('GRID', (0, 0), (-1, -1), 1, colors.black),\n",
    "            ]))\n",
    "        elif title == \"Detailed Analysis\":\n",
    "            draw_wrapped_table(content, TableStyle([\n",
    "                ('BACKGROUND', (0, 0), (-1, 0), colors.lightblue),\n",
    "                ('GRID', (0, 0), (-1, -1), 1, colors.black),\n",
    "                ('ALIGN', (0, 0), (-1, -1), 'LEFT'),\n",
    "                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "                ('TEXTCOLOR', (0, 0), (-1, 0), colors.black),\n",
    "            ]))\n",
    "        else:\n",
    "            write_text_block(content)\n",
    "\n",
    "    # Extract and execute Python code blocks\n",
    "    code_blocks = re.findall(r\"```python(.*?)```\", summary_text, re.DOTALL)\n",
    "    tempdir = tempfile.mkdtemp()\n",
    "\n",
    "    for idx, code in enumerate(code_blocks):\n",
    "        try:\n",
    "            local_env = {\"plt\": plt, \"df\": df[:10]}\n",
    "            exec(code, local_env)\n",
    "            for fname in os.listdir(\"graph\"):\n",
    "                if fname.endswith(\".jpg\"):\n",
    "                    img_path = os.path.join(\"graph\", fname)\n",
    "                    img = ImageReader(img_path)\n",
    "                    img_width, img_height = img.getSize()\n",
    "                    aspect = img_height / float(img_width)\n",
    "                    display_width = max_width\n",
    "                    display_height = display_width * aspect\n",
    "\n",
    "                    if y - display_height < bottom_margin:\n",
    "                        c.showPage()\n",
    "                        c.setFont(\"Helvetica\", 12)\n",
    "                        c.rect(20, 20, width - 40, height - 40)\n",
    "                        y = height - top_margin\n",
    "\n",
    "                    c.drawImage(img, left_margin, y - display_height, width=display_width, height=display_height)\n",
    "                    y -= display_height + 20\n",
    "        except Exception as e:\n",
    "            write_text_block(f\"Do data found for graph \")\n",
    "\n",
    "    c.save()\n",
    "    shutil.rmtree(tempdir)\n",
    "    return filepath\n",
    "\n",
    "\n",
    "# import random\n",
    "r1 = random.randint(1, 1000)\n",
    "DEFAULT_SESSION_ID = \"demo_session_\"+str(r1)\n",
    "DEFAULT_USER_ID = \"user_\"+str(r1)\n",
    "\n",
    "# r1 = random.randint(1, 1000)\n",
    "# DEFAULT_SESSION_ID = \"demo_session_001\"\n",
    "# DEFAULT_USER_ID = \"user_123\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    session_id = gr.Textbox(value=DEFAULT_SESSION_ID, visible=False)\n",
    "    user_id = gr.Textbox(value=DEFAULT_USER_ID, visible=False)\n",
    "    gr.Markdown(\"### Tabular Data Processor\")\n",
    "    text_input = gr.Textbox(lines=3, label=\"Put your Query Here\")\n",
    "\n",
    "    with gr.Row():\n",
    "        submit_btn = gr.Button(\"Submit\")\n",
    "        analyze_btn = gr.Button(\"Analyze\")  # Not wired up\n",
    "\n",
    "    sql_output = gr.Textbox(label=\"Generated SQL Output\")\n",
    "    summary_output = gr.Textbox(label=\"Summary Output\")\n",
    "\n",
    "    result_df_output = gr.Dataframe(\n",
    "        label=\"SQL Result Table\",\n",
    "        interactive=True,\n",
    "        row_count=2,\n",
    "        col_count=(0, \"dynamic\"),\n",
    "        wrap=True,\n",
    "    )\n",
    "\n",
    "    graph_output = gr.Textbox(label=\"Graph Suggestions\")\n",
    "\n",
    "    gr.Markdown(\"### 📊 Generate Custom Graph\")\n",
    "\n",
    "    with gr.Row():\n",
    "        chart_type = gr.Dropdown(choices=[], label=\"Graph Type\")\n",
    "        x_column = gr.Dropdown(choices=[], label=\"X-axis Column\")\n",
    "        y_column = gr.Dropdown(choices=[], label=\"Y-axis Column\")\n",
    "\n",
    "    update_graph_btn = gr.Button(\"Generate Custom Graph\")\n",
    "    custom_graph_output = gr.Image(type=\"filepath\", label=\"Generated Graph\")\n",
    "    data_analysis = gr.Textbox(label=\"summary\", visible=False)\n",
    "\n",
    "    # Submit and dynamically update controls\n",
    "    submit_btn.click(\n",
    "        submit_action,\n",
    "        inputs=[text_input,session_id, user_id],\n",
    "        outputs=[sql_output, summary_output, result_df_output, graph_output, chart_type, data_analysis]\n",
    "    ).then(\n",
    "        lambda df: (\n",
    "            gr.update(choices=list(df.columns)),\n",
    "            gr.update(choices=list(df.select_dtypes(include=\"number\").columns))\n",
    "        ),\n",
    "        inputs=result_df_output,\n",
    "        outputs=[x_column, y_column]\n",
    "    )\n",
    "\n",
    "    with gr.Row():\n",
    "        download_btn = gr.Button(\"Download Summary as PDF\")\n",
    "        pdf_file_output = gr.File(label=\"Download PDF\", interactive=True, type=\"filepath\")\n",
    "    \n",
    "    download_btn.click(\n",
    "        generate_summary_pdf,\n",
    "        inputs=[data_analysis,result_df_output],\n",
    "        outputs=[pdf_file_output]\n",
    "    )\n",
    "\n",
    "    \n",
    "    update_graph_btn.click(\n",
    "        lambda chart_type, x, y, df: create_custom_chart(df, chart_type, x, y),\n",
    "        inputs=[chart_type, x_column, y_column, result_df_output],\n",
    "        outputs=custom_graph_output\n",
    "    )\n",
    "\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv_new)",
   "language": "python",
   "name": "myenv_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
